{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af01aed-46f3-414b-825e-239128b9ffbe",
   "metadata": {},
   "source": [
    "# Modéle de démo make_regression de Scikit-learn\n",
    "\n",
    "Régression simple basée sur un réseau de neurones à 2 couches. \n",
    "\n",
    "Jeux de données jeu de données `make_regression` de Scikit-learn génère des données linéaires avec un bruit, ce qui est parfait pour la régression linéaire.\n",
    "\n",
    "- Déploiement du modèle avec Pytorch\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87eab1-f249-4c0c-8805-d5cce6476e25",
   "metadata": {},
   "source": [
    "# Déclaration du modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d2618-10c4-4098-8fea-fb0823372e1f",
   "metadata": {},
   "source": [
    "## Import des dépendances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3b098d-f382-4583-9807-4e0eed7ffae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Créer un dataset simple pour la régression avec 2 features\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "\n",
    "# Convertir en tensor PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # Reshape pour correspondre à la sortie\n",
    "\n",
    "\n",
    "# Définir un modèle de régression linéaire\n",
    "class LinearRegressionModel2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel2D, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1)  # 2 features d'entrée, 1 sortie\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Créer le modèle\n",
    "model = LinearRegressionModel2D()\n",
    "\n",
    "# Optimiseur et fonction de perte\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_tensor)\n",
    "    \n",
    "    # Calcul de la perte\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    \n",
    "    # Backward pass et optimisation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Affichage des résultats\n",
    "y_pred = model(X_tensor).detach().numpy()\n",
    "\n",
    "# Afficher les données et la droite ajustée\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Données réelles')\n",
    "plt.plot(X[:, 0], y_pred, color='red', label='Régression linéaire')\n",
    "plt.title(\"Régression linéaire 2D avec `make_regression`\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.colorbar(label=\"Label (y)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9ddec-58ae-43d4-be87-c8d1a177cb00",
   "metadata": {},
   "source": [
    "# Définition du modèle (create_model) :\n",
    "\n",
    "On utilise `nn.Sequential`, qui permet de définir une séquence de couches directement dans une fonction.\n",
    "\n",
    "- La première couche est une couche linéaire qui prend un vecteur d'entrée (input_size) et le transforme en un vecteur caché de taille hidden_size.\n",
    "- Ensuite, on applique une activation ReLU pour ajouter de la non-linéarité.\n",
    "- La deuxième couche est une autre couche linéaire qui réduit la taille du vecteur caché à la taille de sortie (output_size).\n",
    "\n",
    "- Transforme l'entrée (input_size) en un vecteur caché (hidden_size).\n",
    "- Activation ReLU (relu) : Introduit une non-linéarité pour améliorer l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d405ab84-b6ed-4330-846e-9723ae7c8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "def create_model(input_size, hidden_size, output_size):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),  # Première couche linéaire\n",
    "        nn.ReLU(),                           # Activation ReLU\n",
    "        nn.Linear(hidden_size, output_size)  # Deuxième couche linéaire\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c1325-d59d-4318-b974-7b26eda3597a",
   "metadata": {},
   "source": [
    "# Dénition de la Fonction de perte (compute_loss) :\n",
    "\n",
    "Cette fonction : \n",
    "- prend le modèle, les entrées et les cibles comme arguments,\n",
    "- fait une prédiction avec le modèle et calcule la perte en utilisant l'erreur quadratique moyenne (Mean Squared Error ou MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcecb0df-9c28-4584-a017-a5e9c015bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de perte (Mean Squared Error)\n",
    "def compute_loss(model, inputs, targets):\n",
    "    outputs = model(inputs)\n",
    "    loss = nn.MSELoss()(outputs, targets)  # Calcul de la perte MSE\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c5dd1-6b48-42db-bda9-8e9b90ec9b7b",
   "metadata": {},
   "source": [
    "## Fonction d'entraînement (train_model) :\n",
    "\n",
    "On utilise un optimiseur Adam avec un taux d'apprentissage configurable pour mettre à jour les paramètres du modèle à chaque itération.\n",
    "\n",
    "On boucle sur chaque époque d'entraînement et sur les batches d'un train_loader (qui contient les données d'entraînement sous forme de mini-lots).\n",
    "\n",
    "À chaque itération, on fait une propagation avant, puis on calcule la perte. Ensuite, on effectue une propagation arrière (loss.backward()) pour calculer les gradients et mettre à jour les poids avec optimizer.step().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4ffab5-4949-45d5-8301-417c91a36fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entraînement\n",
    "def train_model(model, train_loader, learning_rate=0.001, epochs=5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimiseur Adam\n",
    "    \n",
    "    # Boucle d'entraînement\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()  # Réinitialisation des gradients\n",
    "\n",
    "            loss = compute_loss(model, inputs, targets)  # Calcul de la perte\n",
    "            loss.backward()  # Propagation arrière des gradients\n",
    "\n",
    "            optimizer.step()  # Mise à jour des paramètres du modèle\n",
    "\n",
    "            total_loss += loss.item()  # Accumuler la perte pour l'afficher\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa17a9-97b2-4f9a-902e-72eb446eb6b7",
   "metadata": {},
   "source": [
    "# Utilisation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39de4ae-b5a3-4f5c-90fc-3521de4c98b8",
   "metadata": {},
   "source": [
    "## Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7c90ee-910a-4bb7-a660-a167eeb24328",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10  # Exemple de taille d'entrée\n",
    "hidden_size = 20  # Exemple de taille de la couche cachée\n",
    "output_size = 1  # Exemple de taille de sortie (régression)\n",
    "\n",
    "model = create_model(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bc2ec-e499-4489-8a6a-fff4cb2e94ad",
   "metadata": {},
   "source": [
    "## Création d'un jeu de données d'exemple (pour l'entraînement) : Utilise un jeu de données factice pour tester le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89dac210-d5cd-43d3-b941-3bbfe330ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Création de données aléatoires pour l'exemple\n",
    "X_train = torch.randn(100, input_size)  # 100 échantillons, chacun de taille `input_size`\n",
    "y_train = torch.randn(100, output_size)  # 100 étiquettes correspondantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4ce5f6-c12c-487f-bc72-9ad8a5fe9a66",
   "metadata": {},
   "source": [
    "# Ou utiliser le dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3713d9-a076-46e9-a781-d1e7ef7f065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dataset simple pour la régression avec 2 features\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)\n",
    "\n",
    "# Convertir en tensor PyTorch\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # Reshape pour correspondre à la sortie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34752544-c42c-4510-b865-035514e59e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataLoader pour itérer sur les mini-lots\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcee93d8-8988-4e6f-8f23-b73816608df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entraîner le modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0524fc8b-c025-41cd-9593-375ea5106a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0275475127356393\n",
      "Epoch [2/5], Loss: 1.1203798396246774\n",
      "Epoch [3/5], Loss: 0.8862888855593545\n",
      "Epoch [4/5], Loss: 0.9199024183409554\n",
      "Epoch [5/5], Loss: 0.8545659141881126\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, learning_rate=0.001, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cfc48d-644a-434a-a759-1471f414963e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
